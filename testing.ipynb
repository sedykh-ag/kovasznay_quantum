{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 10000 points required, but 10092 points sampled.\n"
     ]
    }
   ],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dde.Model(data, FNN())\n",
    "model.compile() # automatically loads last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training...\n",
      "epoch: 10, loss_train: 1.8568007946014404, loss_test: [0.7743311524391174, 0.2188669741153717, 0.8834730982780457]\n",
      "epoch: 20, loss_train: 1.4906822443008423, loss_test: [1.0415047407150269, 0.21476894617080688, 0.9269061088562012]\n",
      "epoch: 30, loss_train: 1.388631820678711, loss_test: [0.8638588786125183, 0.2187729924917221, 0.9167008399963379]\n",
      "epoch: 40, loss_train: 1.3918803930282593, loss_test: [0.8488472700119019, 0.21897879242897034, 0.9035190343856812]\n",
      "epoch: 50, loss_train: 1.3747316598892212, loss_test: [0.907424807548523, 0.21997837722301483, 0.8910029530525208]\n",
      "epoch: 60, loss_train: 1.3651553392410278, loss_test: [0.8680422902107239, 0.22193798422813416, 0.8674792051315308]\n",
      "epoch: 70, loss_train: 1.360327124595642, loss_test: [0.8779201507568359, 0.2237831950187683, 0.8480705618858337]\n",
      "epoch: 80, loss_train: 1.3560073375701904, loss_test: [0.8776664733886719, 0.2256929576396942, 0.8291909098625183]\n",
      "epoch: 90, loss_train: 1.3521192073822021, loss_test: [0.874330461025238, 0.22818376123905182, 0.8125861287117004]\n",
      "epoch: 100, loss_train: 1.348297119140625, loss_test: [0.8751539587974548, 0.22954130172729492, 0.8059481978416443]\n",
      "Saved checkpoint at models/09-05-2023--20-32-20\n",
      "epoch: 110, loss_train: 1.3439916372299194, loss_test: [0.8716062903404236, 0.23011253774166107, 0.8012027144432068]\n",
      "epoch: 120, loss_train: 1.338464617729187, loss_test: [0.8695499300956726, 0.230054572224617, 0.8015449047088623]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mtrain(\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/utils.py:9\u001b[0m, in \u001b[0;36mtimeit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      8\u001b[0m     t0 \u001b[39m=\u001b[39m perf_counter()\n\u001b[0;32m----> 9\u001b[0m     value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     10\u001b[0m     t1 \u001b[39m=\u001b[39m perf_counter()\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuted in \u001b[39m\u001b[39m{\u001b[39;00mt1\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mt0\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m sec.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/model.py:126\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, epochs, resample)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarted training...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs_run\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 126\u001b[0m     loss_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train_epoch(epoch)\n\u001b[1;32m    127\u001b[0m     loss_test \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_test_epoch(epoch)\n\u001b[1;32m    128\u001b[0m     grad\u001b[39m.\u001b[39mclear() \u001b[39m# clear cached gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/model.py:101\u001b[0m, in \u001b[0;36mModel._run_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     99\u001b[0m pred_pde \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x_pde)\n\u001b[1;32m    100\u001b[0m pred_bc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x_bc)\n\u001b[0;32m--> 101\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mloss(x_pde, x_bc, pred_pde, pred_bc)\n\u001b[1;32m    102\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/data.py:72\u001b[0m, in \u001b[0;36mPDEData.loss\u001b[0;34m(self, x_pde, x_bc, pred_pde, pred_bc, C)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x_pde, x_bc, pred_pde, pred_bc, C\u001b[39m=\u001b[39m[]):\n\u001b[1;32m     70\u001b[0m     \u001b[39m# pde loss\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     loss_pde \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mfor\u001b[39;00m residual \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpde(x_pde, pred_pde):\n\u001b[1;32m     73\u001b[0m         loss_pde\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMSE(residual, torch\u001b[39m.\u001b[39mzeros_like(residual))) \u001b[39m# < (pde_residual)**2 >\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[39m# bc loss\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/main.py:20\u001b[0m, in \u001b[0;36mpde\u001b[0;34m(x, u)\u001b[0m\n\u001b[1;32m     18\u001b[0m v_vel_y \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mjacobian(u, x, i\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m v_vel_xx \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mhessian(u, x, component\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m v_vel_yy \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mhessian(u, x, component\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, i\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, j\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m p_x \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mjacobian(u, x, i\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m p_y \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mjacobian(u, x, i\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/gradients.py:183\u001b[0m, in \u001b[0;36mhessian\u001b[0;34m(ys, xs, component, i, j, grad_y)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhessian\u001b[39m(ys, xs, component\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, grad_y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Hessian matrix H: H[i][j] = d^2y / dx_i dx_j, where i,j=0,...,dim_x-1.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[39m    Use this function to compute second-order derivatives instead of ``tf.gradients()``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39m        H[`i`][`j`].\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mreturn\u001b[39;00m hessian\u001b[39m.\u001b[39;49m_Hessians(ys, xs, component\u001b[39m=\u001b[39;49mcomponent, i\u001b[39m=\u001b[39;49mi, j\u001b[39m=\u001b[39;49mj, grad_y\u001b[39m=\u001b[39;49mgrad_y)\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/gradients.py:151\u001b[0m, in \u001b[0;36mHessians.__call__\u001b[0;34m(self, y, xs, component, i, j, grad_y)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mHs:\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mHs[key] \u001b[39m=\u001b[39m Hessian(y, xs, component\u001b[39m=\u001b[39mcomponent, grad_y\u001b[39m=\u001b[39mgrad_y)\n\u001b[0;32m--> 151\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mHs[key](i, j)\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/gradients.py:133\u001b[0m, in \u001b[0;36mHessian.__call__\u001b[0;34m(self, i, j)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    132\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns H[`i`][`j`].\"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH(i, j)\n",
      "File \u001b[0;32m~/GitHub/kovasznay_quantum/lightdde/gradients.py:37\u001b[0m, in \u001b[0;36mJacobian.__call__\u001b[0;34m(self, i, j)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mJ:\n\u001b[1;32m     36\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mys[:, i : i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_y \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mys\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mJ[i] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(\n\u001b[1;32m     38\u001b[0m         y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxs, grad_outputs\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mones_like(y), create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m     42\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mJ[i] \u001b[39mif\u001b[39;00m j \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_x \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mJ[i][:, j : j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m     43\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[1;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
